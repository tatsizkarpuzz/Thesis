{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc1231-6a6e-47a8-aede-56fa4382a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import math\n",
    "import scipy.stats\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "import colorama\n",
    "from colorama import Fore, Style\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d2cdc-0c8c-42a3-9020-c1b52ce45eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Primary total energy consumption.csv',delimiter=';')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385bc6a5-3609-4b8b-bddd-8872ee09737f",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Handle Missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd32fc-113b-4f59-922a-c2d12cf05c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorganize data columns\n",
    "df1 = pd.melt(df, id_vars=[\"Country\"], var_name=\"Year\", value_name=\"Value\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0443bfd7-a744-4fbb-aefe-92ed0d699ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminate the countries which are not in European Union\n",
    "values = ['Iceland','Norway','Switzerland','Turkey','Ukraine', 'United Kingdom', 'Other Europe']\n",
    "df1 = df1[df1.Country.isin(values) == False]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706bd6fb-34ea-440b-bcef-be7435aa96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d016bf-3d78-4c61-8192-08c0e89dd07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a619a8c0-d33a-4a5d-9aab-f70033475ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().sum() #sum of null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2baeb2-4dfe-41e1-bbc1-72a10aa34cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"Value\"] =[float(str(i).replace(',','.')) for i in df1[\"Value\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0cc39f-efcf-45ad-a9f0-77e512c41cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null data with the mean of each group\n",
    "df1['Value']= df1.groupby('Country')['Value'].apply(lambda x: x.fillna(x.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b079998-312c-4c24-87e1-f980d2c1e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#round up after comma\n",
    "df1['Value']=round(df1['Value'],2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788c70dd-61f5-425b-a8eb-089dcd475926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1308a56e-f447-4491-9808-acada7ccbd7d",
   "metadata": {},
   "source": [
    "## Training and Testing the SVR model - Accuracy Metrics for Time Series Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986c0e9a-eea6-47d6-9332-8d5fc4c3b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_name=df1['Country'].unique()\n",
    "print(country_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421aeab-db4b-4daa-b9d1-008e64d53d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and testing datasets\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dict_org = {}\n",
    "dict_pred = {}\n",
    "country_accuracy = {}\n",
    "\n",
    "for name in range(len(country_name)):\n",
    "    X = df1[df1['Country'] == country_name[name]][['Year','Value']]\n",
    "    X[\"Value\"] =[float(str(i).replace(',','.')) for i in X[\"Value\"]] \n",
    "    X['Value']= X['Value'].fillna(X['Value'].mean())\n",
    "    X['Value']=round(X['Value'],2) \n",
    "    X['Year'] = pd.to_datetime(X['Year']) #convert Year column to datetime\n",
    "    X = X.set_index(X.columns[0])\n",
    "    size = int(len(X) * 0.70)\n",
    "    train, test = X[0:size], X[size:len(X)]\n",
    "\n",
    "    #print(train,test)\n",
    "    #print(train.shape,test.shape)\n",
    "    # prepare data for standardization\n",
    "    train_values = train['Value'].values\n",
    "    test_values = test['Value'].values\n",
    "    #print(train_values)\n",
    "    train_values = train_values.reshape((len(train_values), 1))\n",
    "    test_values = test_values.reshape((len(test_values), 1))\n",
    "    #print(train_values)\n",
    "    #print(test_values)\n",
    "    scaler = MinMaxScaler()\n",
    "    train_data = scaler.fit_transform(train_values) #Scale the training data to be in the range (0, 1)\n",
    "    test_data = scaler.transform(test_values) #scale the testing data\n",
    "    #print(train_data.shape)\n",
    "    #print(test_data.shape)\n",
    "    \n",
    "    #Create data with time-steps\n",
    "    timesteps=5\n",
    "    train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,0]\n",
    "    #print(train_data_timesteps.shape)\n",
    "    \n",
    "    test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,0]\n",
    "\n",
    "    x_train, y_train = train_data_timesteps[:,:timesteps-1],train_data_timesteps[:,[timesteps-1]]\n",
    "    x_test, y_test = test_data_timesteps[:,:timesteps-1],test_data_timesteps[:,[timesteps-1]]\n",
    "    #print(x_train.shape, y_train.shape)\n",
    "    #print(x_test.shape, y_test.shape)\n",
    "    \n",
    "    ## Implement SVR\n",
    "    model = SVR(kernel='rbf',gamma=0.5, C=10, epsilon = 0.05)\n",
    "    \n",
    "    ## Prepare the model for the training data by calling the fit() function\n",
    "    model.fit(x_train, y_train[:,0])\n",
    "    SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.05, gamma=0.5,\n",
    "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "    \n",
    "    ## Make model predictions\n",
    "    y_train_pred = model.predict(x_train).reshape(-1,1)\n",
    "    y_test_pred = model.predict(x_test).reshape(-1,1)\n",
    "    #print(y_train_pred.shape, y_test_pred.shape)\n",
    "    \n",
    "    ##Evaluate your model \n",
    "    # Scaling the predictions\n",
    "    y_train_pred = scaler.inverse_transform(y_train_pred)\n",
    "    y_test_pred = scaler.inverse_transform(y_test_pred)\n",
    "\n",
    "    #print(len(y_train_pred), len(y_test_pred))\n",
    "    \n",
    "    # Scaling the original values\n",
    "    y_train = scaler.inverse_transform(y_train)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "    #print(len(y_train), len(y_test))\n",
    "    \n",
    "    ## Check model performance on training and testing data\n",
    "    \n",
    "    train_timestamps = train.index[timesteps-1:]\n",
    "    \n",
    "    test_timestamps = test.index[timesteps-1:]\n",
    "    #print(train_timestamps)\n",
    "    #print(test_timestamps)\n",
    "\n",
    "    #print(len(train_timestamps), len(test_timestamps))\n",
    "    plt.figure(figsize=(25,6))\n",
    "    plt.plot(train_timestamps, y_train, color = 'red', linewidth=2.0, alpha = 0.6)\n",
    "    plt.plot(train_timestamps, y_train_pred, color = 'blue', linewidth=0.8)\n",
    "    plt.legend(['Actual','Predicted'])\n",
    "    plt.xlabel('Year')\n",
    "    plt.title(country_name[name])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    #Print model checking for training data\n",
    "    print('MAPE for training data: {}'.format(country_name[name]), np.mean(np.abs((y_train - y_train_pred) / y_train))*100, '%')\n",
    "    \n",
    "    # Plot the predictions for testing data\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.plot(test_timestamps, y_test, color = 'red', linewidth=2.0, alpha = 0.4)\n",
    "    plt.plot(test_timestamps, y_test_pred, color = 'blue', linewidth=0.8)\n",
    "    plt.legend(['Actual','Predicted'])\n",
    "    plt.xlabel(country_name[name])\n",
    "    plt.show()\n",
    "    \n",
    "    #Print model checking for testing data\n",
    "    mse= mean_squared_error(y_test, y_test_pred)\n",
    "    mae=mean_absolute_error(y_test, y_test_pred)\n",
    "    rmse_test=sqrt(mse) #RMSE\n",
    "    mape_test=np.mean(np.abs(y_test_pred-y_test)/np.abs(y_test)) #Mean absolute percentage error\n",
    "    print('MAE for test data {} :'.format(country_name[name]),mae) \n",
    "    print('MAPE for test data  {} :'.format(country_name[name]),mape_test)\n",
    "    print('RMSE for test data {} :'.format(country_name[name]),rmse_test)\n",
    "    print('MSE for test data {} :'.format(country_name[name]),mse)\n",
    "   \n",
    "        \n",
    "    \n",
    "   \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aa7d85-19e7-414d-90d1-45bdd468a371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c845b8f2-23c0-4554-98a8-db09c81fccc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957107d7-6ffc-44b3-aae0-6ac4fdc3d532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ababec71-818e-493d-a37b-4f73129e1194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

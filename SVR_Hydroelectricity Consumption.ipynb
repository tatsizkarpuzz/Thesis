{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f428abfe-f534-493a-b26e-c1b6b663181a",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40869ab-a10c-4453-bfd7-fef0f54b0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "import colorama\n",
    "from colorama import Fore, Style\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798a7d9f-c5e4-47c1-b05d-21ad87bfea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Hydroelectricity Consumption at disaggregate level.csv',delimiter=';')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2c4056-e075-46b1-821f-3f60c91ed781",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Handle Missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585f6c8f-6156-479e-a8e1-b36854068807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorganize data columns\n",
    "df1 = pd.melt(df, id_vars=[\"Country\"], var_name=\"Year\", value_name=\"Value\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a6e93e-c9d8-4fa1-aeac-ab2d6dc14ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the countries which are not in European Union\n",
    "values = ['Iceland','Norway','Switzerland','Turkey','Ukraine', 'United Kingdom', 'Other Europe']\n",
    "df1 = df1[df1.Country.isin(values) == False]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75954b11-4382-4180-863b-f1c0032bf7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c405c58-be4a-4e3c-bbba-3bedb058554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f88bb4-28fd-465f-9d88-188d36a27beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8772c2-43ff-4afa-85c6-280d5ebe360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert datatype from string to float\n",
    "df1[\"Value\"] =[float(str(i).replace(',','.')) for i in df1[\"Value\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca9d4f-b1d1-4a5a-ac28-882763ac4e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null data with the mean of each group\n",
    "df1['Value']= df1.groupby('Country')['Value'].apply(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b03bdc8-aa86-4266-97f2-b60f63ee7266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#round up after comma\n",
    "df1['Value']=round(df1['Value'],2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5f693d-fb65-4dd8-bedb-a0062c6fba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaf6de3-51ca-4b67-b857-7e965504bf8b",
   "metadata": {},
   "source": [
    "## Training and Testing the SVR model - Accuracy Metrics for Time Series Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0b3178-ccbe-4507-99b8-4071fb40bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_name=df1['Country'].unique()\n",
    "print(country_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b4b9a0-72d5-4d83-acbb-45b50b47e723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and testing datasets\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dict_org = {}\n",
    "dict_pred = {}\n",
    "country_accuracy = {}\n",
    "for name in range(len(country_name)):\n",
    "    X = df1[df1['Country'] == country_name[name]][['Year','Value']]\n",
    "    X[\"Value\"] =[float(str(i).replace(',','.')) for i in X[\"Value\"]] \n",
    "    X['Value']= X['Value'].fillna(X['Value'].mean())\n",
    "    X['Value']=round(X['Value'],2) \n",
    "    X['Year'] = pd.to_datetime(X['Year']) #convert Year column to datetime\n",
    "    X = X.set_index(X.columns[0])\n",
    "    size = int(len(X) * 0.70)\n",
    "    train, test = X[0:size], X[size:len(X)]\n",
    "\n",
    "    #print(train,test)\n",
    "    #print(train.shape,test.shape)\n",
    "    # prepare data for standardization\n",
    "    train_values = train['Value'].values\n",
    "    test_values = test['Value'].values\n",
    "    #print(train_values)\n",
    "    train_values = train_values.reshape((len(train_values), 1))\n",
    "    test_values = test_values.reshape((len(test_values), 1))\n",
    "    #print(train_values)\n",
    "    #print(test_values)\n",
    "    scaler = MinMaxScaler()\n",
    "    train_data = scaler.fit_transform(train_values) #Scale the training data to be in the range (0, 1)\n",
    "    test_data = scaler.transform(test_values) #scale the testing data\n",
    "    #print(train_data.shape)\n",
    "    #print(test_data.shape)\n",
    "    \n",
    "    #Create data with time-steps\n",
    "    timesteps=3\n",
    "    train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,0]\n",
    "    #print(train_data_timesteps.shape)\n",
    "    \n",
    "    test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,0]\n",
    "\n",
    "    x_train, y_train = train_data_timesteps[:,:timesteps-1],train_data_timesteps[:,[timesteps-1]]\n",
    "    x_test, y_test = test_data_timesteps[:,:timesteps-1],test_data_timesteps[:,[timesteps-1]]\n",
    "    #print(x_train.shape, y_train.shape)\n",
    "    #print(x_test.shape, y_test.shape)\n",
    "    \n",
    "    ## Implement SVR\n",
    "    model = SVR(kernel='rbf',gamma=0.7, C=10, epsilon = 0.05)\n",
    "    \n",
    "    ## Prepare the model for the training data by calling the fit() function\n",
    "    model.fit(x_train, y_train[:,0])\n",
    "    SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.05, gamma=0.7,\n",
    "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "    \n",
    "    ## Make model predictions\n",
    "    y_train_pred = model.predict(x_train).reshape(-1,1)\n",
    "    y_test_pred = model.predict(x_test).reshape(-1,1)\n",
    "    #print(y_train_pred.shape, y_test_pred.shape)\n",
    "    \n",
    "    ##Evaluate your model \n",
    "    # Scaling the predictions\n",
    "    y_train_pred = scaler.inverse_transform(y_train_pred)\n",
    "    y_test_pred = scaler.inverse_transform(y_test_pred)\n",
    "\n",
    "    #print(len(y_train_pred), len(y_test_pred))\n",
    "    \n",
    "    # Scaling the original values\n",
    "    y_train = scaler.inverse_transform(y_train)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "    #print(len(y_train), len(y_test))\n",
    "    \n",
    "    ## Check model performance on training and testing data\n",
    "    \n",
    "    train_timestamps = train.index[timesteps-1:]\n",
    "    \n",
    "    test_timestamps = test.index[timesteps-1:]\n",
    "    #print(train_timestamps)\n",
    "    #print(test_timestamps)\n",
    "\n",
    "    #print(len(train_timestamps), len(test_timestamps))\n",
    "    plt.figure(figsize=(25,6))\n",
    "    plt.plot(train_timestamps, y_train, color = 'red', linewidth=2.0, alpha = 0.6)\n",
    "    plt.plot(train_timestamps, y_train_pred, color = 'blue', linewidth=0.8)\n",
    "    plt.legend(['Actual','Predicted'])\n",
    "    plt.xlabel('Year')\n",
    "    plt.title(country_name[name])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    #Print model checking for training data\n",
    "    mape_train=np.mean(np.abs(y_train_pred-y_train)/np.abs(y_train)) #Mean absolute percentage error\n",
    "    print('MAPE for train data  {} :'.format(country_name[name]),mape_train)\n",
    "    # Plot the predictions for testing data\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.plot(test_timestamps, y_test, color = 'red', linewidth=2.0, alpha = 0.4)\n",
    "    plt.plot(test_timestamps, y_test_pred, color = 'blue', linewidth=0.8)\n",
    "    plt.legend(['Actual','Predicted'])\n",
    "    plt.xlabel(country_name[name])\n",
    "    plt.show()\n",
    "    \n",
    "    #Print model checking for testing data\n",
    "    mse= mean_squared_error(y_test, y_test_pred)\n",
    "    mae=mean_absolute_error(y_test, y_test_pred)\n",
    "    rmse_test=sqrt(mse) #RMSE\n",
    "    mape_test=np.mean(np.abs(y_test_pred-y_test)/np.abs(y_test)) #Mean absolute percentage error\n",
    "    print('MAE for test data {} :'.format(country_name[name]),mae) \n",
    "    print('MAPE for test data  {} :'.format(country_name[name]),mape_test)\n",
    "    print('RMSE for test data {} :'.format(country_name[name]),rmse_test)\n",
    "    print('MSE for test data {} :'.format(country_name[name]),mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b9046-7645-4cc0-9dc6-5e617afcd5af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
